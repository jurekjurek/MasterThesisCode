{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikipedia2vec import Wikipedia2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .txt data\n",
    "# data = open('../datasets/enwiki_20180420_100d.txt', 'r')\n",
    "\n",
    "# print('start reading.')\n",
    "\n",
    "# content = data.read()\n",
    "\n",
    "# print('read content')\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# pickleFile = open('pickleWikipediaWords', 'ab')\n",
    "\n",
    "# print('start dumping')\n",
    "\n",
    "# pickle.dump(content, pickleFile)\n",
    "\n",
    "# print('dumped to pickle file.')\n",
    "\n",
    "# pickleFile.close()\n",
    "# data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob/anaconda3/envs/code/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-0.12560804 -0.5235532  -0.13231167 ... -0.48633438  0.45111445\n",
      "   0.11309847]\n",
      " [-0.12473089 -0.6455471   0.13622157 ... -0.6347396   0.5410465\n",
      "   0.32159257]\n",
      " [-0.05129661 -0.4987064  -0.09563554 ... -0.30148467  0.24280211\n",
      "  -0.08308805]\n",
      " ...\n",
      " [-1.0583687  -0.83086014 -0.4427682  ... -1.0160557  -0.02469787\n",
      "   0.99688977]\n",
      " [-1.0772408  -0.32139003 -0.79673034 ... -1.3150353  -0.12155519\n",
      "   0.57841384]\n",
      " [-0.86319923 -0.5425662  -0.5506818  ... -1.1069874   0.26995388\n",
      "   0.43403685]] loaded from the file ../datasets/enwiki_20180420_100d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/home/bob/anaconda3/envs/code/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[ 9.31275263e-02 -8.88679624e-02 -1.91727564e-01 ... -1.34685934e-01\n",
      "  -1.15518689e-01  1.95024401e-01]\n",
      " [ 1.06650688e-01 -1.39282122e-01  1.28345221e-01 ... -2.58541018e-01\n",
      "   1.06945192e-03  4.36867744e-01]\n",
      " [ 2.41883561e-01 -3.22016366e-02 -1.21213362e-01 ...  2.10319590e-02\n",
      "  -3.88098627e-01 -7.62230903e-02]\n",
      " ...\n",
      " [-6.40646815e-01  2.35682666e-01  2.19560400e-01 ...  1.07549876e-01\n",
      "  -1.31226122e+00  1.51679659e+00]\n",
      " [-2.97203183e-01  2.59723127e-01  2.77167350e-01 ... -1.70121565e-01\n",
      "  -1.67249894e+00  1.12165082e+00]\n",
      " [-6.73093140e-01  2.12552413e-01  4.16892409e-01 ...  2.12317891e-02\n",
      "  -1.37761509e+00  6.29351258e-01]] loaded from the file ../datasets/enwiki_20180420_100d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/home/bob/anaconda3/envs/code/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[769702 380730]\n",
      " [649936 302186]\n",
      " [869658 382059]\n",
      " ...\n",
      " [     0      0]\n",
      " [     0      0]\n",
      " [     0      0]] loaded from the file ../datasets/enwiki_20180420_100d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/home/bob/anaconda3/envs/code/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[262 221]\n",
      " [132 108]\n",
      " [124 104]\n",
      " ...\n",
      " [  0   0]\n",
      " [  0   0]\n",
      " [  0   0]] loaded from the file ../datasets/enwiki_20180420_100d.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.26157779 -0.06324237  0.01413879  0.3471325  -0.03113616  0.04367286\n",
      "  0.16051093  0.13918966  0.4020053   0.02132417  0.4937738  -0.19357482\n",
      "  0.16570787  0.20006967  0.46038646  0.11534599 -0.07132792  0.06508564\n",
      "  0.33278874 -0.3134719   0.23085992 -0.34622437  0.03082101  0.506029\n",
      " -0.45648044 -0.16179349 -0.55180806 -0.48477042  0.39876133  0.35310695\n",
      " -0.02152728 -0.09419352  0.3356566   0.7128895  -0.16417094 -0.21861316\n",
      "  0.23070154  0.420371    0.08505379  0.22867164 -0.10435292 -0.23085395\n",
      " -0.5007337   0.32013428  0.06766731  0.25432208 -0.19289295  0.32780027\n",
      " -0.27101117  0.29084572  0.12556057 -0.06193651  0.16854699  0.58460623\n",
      "  0.11538803  0.0525699  -0.17319302  0.17267288  0.00414904  0.2039684\n",
      " -0.19071926 -0.251641    0.06552824  0.2605905   0.5945521  -0.6533295\n",
      " -0.32521802 -0.3095794  -0.30898058 -0.3941069   0.04687437  0.3577981\n",
      "  0.12849359  0.3052618  -0.26543605  0.51226574 -0.12460668  0.2912351\n",
      " -0.06106061 -0.30229414 -0.4071444  -0.48364484  0.2612865  -0.01322418\n",
      "  0.3643194   0.6270434  -0.08800114 -0.15298724  0.19146484  0.08867226\n",
      "  0.278045    0.14740862  0.24092066 -0.0447019  -0.3842921  -0.6271196\n",
      " -0.00376431  0.0373864  -0.2529332   0.20160218]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ItemWithScore(item=<Word nail>, score=1.0),\n",
       " ItemWithScore(item=<Word hurriquake>, score=0.7744725942611694),\n",
       " ItemWithScore(item=<Word nails>, score=0.7489219307899475),\n",
       " ItemWithScore(item=<Word fingernails>, score=0.7278966307640076),\n",
       " ItemWithScore(item=<Word toenail>, score=0.7257317900657654),\n",
       " ItemWithScore(item=<Word shoe>, score=0.714025616645813),\n",
       " ItemWithScore(item=<Word hoof>, score=0.7137674689292908),\n",
       " ItemWithScore(item=<Word glue>, score=0.7104105949401855),\n",
       " ItemWithScore(item=<Word fingernail>, score=0.7092493772506714),\n",
       " ItemWithScore(item=<Word splint>, score=0.7087520956993103)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki2vec = Wikipedia2Vec.load(\"../datasets/enwiki_20180420_100d.pkl\")\n",
    "print(wiki2vec.get_word_vector(\"account\"))\n",
    "wiki2vec.most_similar(wiki2vec.get_word('nail'),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define nouns \n",
    "nouns= [\n",
    "    \"man\",\n",
    "    'woman',\n",
    "    'person',\n",
    "    'dinner',\n",
    "    'meal',\n",
    "    'sauce',\n",
    "    'program',\n",
    "    \"application\",\n",
    "    \"software\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "vecs = []\n",
    "for noun in nouns:\n",
    "    if noun == \"charge_n\":\n",
    "        vecs.append(wiki2vec.get_word_vector(\"charge\").tolist())\n",
    "    else:\n",
    "        vecs.append(wiki2vec.get_word_vector(noun).tolist())\n",
    "vecs = np.array(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 100)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35410539 0.26345813 0.15045848 0.06934345]\n"
     ]
    }
   ],
   "source": [
    "# do PCA \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=4)\n",
    "vecs_new = pca.fit_transform(vecs)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "[[ 0.66429603 -0.54404025  1.49939577 -0.98605524]\n",
      " [ 1.91903733 -0.25475082 -1.35628697 -0.22165542]\n",
      " [-1.10981432  2.05853645 -0.28236348 -0.4811538 ]\n",
      " [-1.89954249 -1.57877889 -0.53063466  0.07442904]\n",
      " [ 0.42602345  0.31903351  0.66988934  1.61443542]]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(vecs_new))\n",
    "\n",
    "print(vecs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_rows = np.linalg.norm(vecs_new,axis=1)\n",
    "normalized_array = vecs_new / sum_of_rows[:, np.newaxis]\n",
    "\n",
    "new_noun_vectors = {}\n",
    "for i, noun in enumerate(nouns):\n",
    "   new_noun_vectors[noun] = normalized_array[i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'man': [-0.2370557742915931, 0.8594845323830477, 0.3846999454317827, 0.23894947259638483], 'woman': [-0.27951714077436546, 0.935316671360229, 0.19839348423523656, 0.08770927945176635], 'person': [-0.5346517001188761, 0.6661434501746717, 0.2699187981144731, -0.4444595659605252], 'dinner': [0.6136596314966611, 0.19067233708423176, -0.7235016261132731, -0.2522128338401291], 'meal': [0.8054883467263027, -0.09811703566160111, -0.5492470411677177, -0.199722954037874], 'sauce': [0.8385219988829802, -0.272232903723701, 0.4566207580609005, 0.11944700426273665], 'program': [-0.46350928959134563, -0.24974397395730483, -0.5136348749891828, 0.6774705167971413], 'application': [-0.6637098891095032, -0.7318362754419938, 0.041285636954133134, -0.148997802758069], 'software': [-0.6244912758334976, -0.7379779308107106, 0.19104097608762097, -0.17000754541984703]}\n"
     ]
    }
   ],
   "source": [
    "print(new_noun_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
